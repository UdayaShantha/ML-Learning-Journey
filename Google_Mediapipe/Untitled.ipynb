{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841049e5-3905-4bcf-959f-070edda703d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe==0.10.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (0.10.20)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (0.4.38)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (0.4.38)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (3.8.4)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe==0.10.20) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe==0.10.20) (1.16.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax->mediapipe==0.10.20) (0.4.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax->mediapipe==0.10.20) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax->mediapipe==0.10.20) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe==0.10.20) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe==0.10.20) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe==0.10.20) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe==0.10.20) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe==0.10.20) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe==0.10.20) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe==0.10.20) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe==0.10.20) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.20) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.20) (1.16.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe==0.10.20 \n",
    "!pip install opencv-python numpy tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e54e4b4-eb58-418f-88c9-5ecd613473e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _framework_bindings: A dynamic link library (DLL) initialization routine failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mediapipe\\__init__.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 - 2022 The MediaPipe Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msolutions\u001b[39;00m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtasks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mediapipe\\python\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020-2021 The MediaPipe Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Python API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_framework_bindings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_ckpt_util\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_framework_bindings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_util\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_framework_bindings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalculator_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CalculatorGraph\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _framework_bindings: A dynamic link library (DLL) initialization routine failed."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "class EnhancedFaceDetector:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Enhanced Face Detection model with key components\n",
    "        \"\"\"\n",
    "        # MediaPipe face detection setup\n",
    "        self.mp_face_detection = mp.solutions.face_detection\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "        # Model parameters\n",
    "        self.input_shape = (224, 224, 3)  # Standard image size\n",
    "        self.model = None\n",
    "\n",
    "    def load_dataset(self, image_dir, mask_dir=None):\n",
    "        \"\"\"\n",
    "        Load images from local directories\n",
    "        \n",
    "        Args:\n",
    "            image_dir (str): Path to directory containing face images\n",
    "            mask_dir (str, optional): Path to directory containing mask images\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Loaded images and labels\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # Load images\n",
    "        for filename in os.listdir(image_dir):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(image_dir, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                # Preprocess image\n",
    "                img = cv2.resize(img, (self.input_shape[0], self.input_shape[1]))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = img / 255.0  # Normalize pixel values\n",
    "                \n",
    "                images.append(img)\n",
    "                \n",
    "                # Simple binary label - face present or not\n",
    "                labels.append(1 if self._detect_face_mediapipe(img) else 0)\n",
    "        \n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "    def _detect_face_mediapipe(self, image):\n",
    "        \"\"\"\n",
    "        Use MediaPipe to detect if a face is present\n",
    "        \n",
    "        Args:\n",
    "            image (np.array): Input image\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if face detected, False otherwise\n",
    "        \"\"\"\n",
    "        with self.mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "            results = face_detection.process(image)\n",
    "            return results.detections is not None and len(results.detections) > 0\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a convolutional neural network for face detection\n",
    "        \n",
    "        Returns:\n",
    "            tf.keras.Model: Compiled face detection model\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            # Convolutional layers for feature extraction\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            \n",
    "            # Flatten and dense layers for classification\n",
    "            Flatten(),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(1, activation='sigmoid')  # Binary classification\n",
    "        ])\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def train_model(self, image_dir, validation_split=0.2, epochs=10):\n",
    "        \"\"\"\n",
    "        Train the face detection model\n",
    "        \n",
    "        Args:\n",
    "            image_dir (str): Directory containing training images\n",
    "            validation_split (float): Percentage of data for validation\n",
    "            epochs (int): Number of training epochs\n",
    "        \"\"\"\n",
    "        # Load dataset\n",
    "        X, y = self.load_dataset(image_dir)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=validation_split, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        # Create and train model\n",
    "        self.model = self.create_model()\n",
    "        \n",
    "        # Training with data augmentation\n",
    "        self.model.fit(\n",
    "            datagen.flow(X_train, y_train, batch_size=32),\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs\n",
    "        )\n",
    "\n",
    "    def save_model(self, output_path='face_detection_model.pickle'):\n",
    "        \"\"\"\n",
    "        Save the trained model to a pickle file\n",
    "        \n",
    "        Args:\n",
    "            output_path (str): Path to save the model\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'model': self.model,\n",
    "                'input_shape': self.input_shape\n",
    "            }, f)\n",
    "        \n",
    "        print(f\"Model saved to {output_path}\")\n",
    "\n",
    "    def load_saved_model(self, model_path='face_detection_model.pickle'):\n",
    "        \"\"\"\n",
    "        Load a previously saved model\n",
    "        \n",
    "        Args:\n",
    "            model_path (str): Path to the saved model file\n",
    "        \n",
    "        Returns:\n",
    "            object: Loaded model\n",
    "        \"\"\"\n",
    "        with open(model_path, 'rb') as f:\n",
    "            saved_data = pickle.load(f)\n",
    "        \n",
    "        self.model = saved_data['model']\n",
    "        self.input_shape = saved_data['input_shape']\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"\n",
    "        Predict face detection on a single image\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Prediction result and confidence\n",
    "        \"\"\"\n",
    "        # Load and preprocess image\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, (self.input_shape[0], self.input_shape[1]))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Predict\n",
    "        prediction = self.model.predict(img)[0][0]\n",
    "        return (prediction > 0.5, prediction)\n",
    "\n",
    "# Usage Example\n",
    "def main():\n",
    "    # Initialize the face detector\n",
    "    face_detector = EnhancedFaceDetector()\n",
    "    \n",
    "    # Training\n",
    "    # Specify the path to your local image directory\n",
    "    training_image_dir = 'C:/Users/User/Downloads/Face_Recognition dataset/train/images'\n",
    "    face_detector.train_model(training_image_dir)\n",
    "    \n",
    "    # Save the model\n",
    "    face_detector.save_model('enhanced_face_detection_model.pickle')\n",
    "    \n",
    "    # Load and test the model\n",
    "    loaded_model = face_detector.load_saved_model('enhanced_face_detection_model.pickle')\n",
    "    \n",
    "    # Predict on a new image\n",
    "    test_image_path = 'C:/Users/User/Downloads/Face_Recognition dataset/train/images/0133_4.jpg'\n",
    "    result, confidence = face_detector.predict(test_image_path)\n",
    "    print(f\"Face Detected: {result}, Confidence: {confidence}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d55fe-361d-4202-b787-35e0d407f12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
